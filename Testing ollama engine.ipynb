{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c26c49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "import msvcrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "362542af",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_MODEL = \"mistral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62bc8461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading turbo model on cuda...\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import speech_recognition as sr\n",
    "import torch\n",
    "import numpy as np\n",
    "import wave\n",
    "\n",
    "MODEL_NAME = \"turbo\" \n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Loading {MODEL_NAME} model on {device}...\")\n",
    "model = whisper.load_model(MODEL_NAME, device=device)\n",
    "\n",
    "def audio_by_user():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone(sample_rate=16000) as source: # Force 16kHz\n",
    "        print(\"Say: 'Robot, move forward one meter.'\")\n",
    "        \n",
    "        print(\"Listening...\")\n",
    "        audio = recognizer.listen(source, timeout=6, phrase_time_limit=10)\n",
    "        \n",
    "        with open(\"debug_audio.wav\", \"wb\") as f:\n",
    "            f.write(audio.get_wav_data())\n",
    "        print(\"Audio saved to 'debug_audio.wav'. Listen to it to check for noise/static.\")\n",
    "\n",
    "        # Transcribe\n",
    "        audio_data = np.frombuffer(audio.get_raw_data(), np.int16).flatten().astype(np.float32) / 32768.0\n",
    "        result = model.transcribe(audio_data, language=\"en\", fp16=torch.cuda.is_available())\n",
    "        \n",
    "        user_speech = print(f\"\\nWhisper Result: \\\"{result['text'].strip()}\\\"\")\n",
    "\n",
    "    return user_speech\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02ee690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_by_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bfe322e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mission_plan(user_input):\n",
    "    print(f\"[BRAIN] Processing logic with {LLM_MODEL}...\")\n",
    "\n",
    "    # STRICT System Prompt\n",
    "    # We tell the LLM exactly what objects exist so it doesn't hallucinate \"yellow_box\"\n",
    "    system_manual = \"\"\"\n",
    "    You are a Robot Logic Unit.\n",
    "    \n",
    "    ENVIRONMENT:\n",
    "    - OBJECTS: ['red_box', 'green_box', 'blue_box']\n",
    "    - LOCATIONS: ['home_position', 'table_center']\n",
    "    \n",
    "    COMMANDS ALLOWED:\n",
    "    - 'pick_up(target)'\n",
    "    - 'move_to(target)'\n",
    "    - 'place_at(target)'\n",
    "    \n",
    "    TASK:\n",
    "    Output a JSON object containing a list of actions based on the user's command.\n",
    "    \n",
    "    Example Input: \"Grab the red box and put it on the table.\"\n",
    "    Example Output: {\n",
    "        \"plan\": [\n",
    "            {\"action\": \"pick_up\", \"target\": \"red_box\"},\n",
    "            {\"action\": \"place_at\", \"target\": \"table_center\"}\n",
    "        ]\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = ollama.generate(\n",
    "            model=LLM_MODEL,\n",
    "            system=system_manual,\n",
    "            prompt=f\"User Command: {user_input}\",\n",
    "            format=\"json\",  # Forces JSON output mode in Ollama\n",
    "            options={\"temperature\": 0} # 0 makes it deterministic (logic > creativity)\n",
    "        )\n",
    "        \n",
    "        raw_response = response['response']\n",
    "        print(f\"[BRAIN] Raw Model Output: {raw_response}\") # Debug print\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = json.loads(raw_response)\n",
    "        \n",
    "        # Normalize: Try to find a list of actions\n",
    "        if \"plan\" in data:\n",
    "            return data[\"plan\"]\n",
    "        elif isinstance(data, list):\n",
    "            return data\n",
    "        else:\n",
    "            # If it returns a single object, wrap it in a list\n",
    "            return [data]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[BRAIN] Error: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e50281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say: 'Robot, move forward one meter.'\n",
      "Listening...\n",
      "Audio saved to 'debug_audio.wav'. Listen to it to check for noise/static.\n",
      "\n",
      "Whisper Result: \"Pick up the red box.\"\n",
      "[BRAIN] Processing logic with mistral...\n",
      "[BRAIN] Raw Model Output: {\n",
      "    \"plan\": [\n",
      "        {\"action\": \"select_object\", \"target\": \"red_box\"},\n",
      "        {\"action\": \"move_to\", \"target\": \"home_position\"},\n",
      "        {\"action\": \"pick_up\", \"target\": \"red_box\"},\n",
      "        {\"action\": \"move_to\", \"target\": \"table_center\"},\n",
      "        {\"action\": \"place_at\", \"target\": \"table_center\"}\n",
      "    ]\n",
      "}\n",
      "\n",
      "[VERIFICATION RESULT]\n",
      "[\n",
      "    {\n",
      "        \"action\": \"select_object\",\n",
      "        \"target\": \"red_box\"\n",
      "    },\n",
      "    {\n",
      "        \"action\": \"move_to\",\n",
      "        \"target\": \"home_position\"\n",
      "    },\n",
      "    {\n",
      "        \"action\": \"pick_up\",\n",
      "        \"target\": \"red_box\"\n",
      "    },\n",
      "    {\n",
      "        \"action\": \"move_to\",\n",
      "        \"target\": \"table_center\"\n",
      "    },\n",
      "    {\n",
      "        \"action\": \"place_at\",\n",
      "        \"target\": \"table_center\"\n",
      "    }\n",
      "]\n",
      ">> STATUS: SUCCESS (Plan Generated)\n",
      "[SYSTEM] Mission complete. Stopping script.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        if msvcrt.kbhit():\n",
    "            if msvcrt.getch() == b'\\x1b': # \\x1b is the ESC key code\n",
    "                print(\"\\n[SYSTEM] ESC pressed. Exiting...\")\n",
    "                break\n",
    "\n",
    "        # 2. Run the Listen Cycle\n",
    "        command = audio_by_user()\n",
    "        \n",
    "        # 3. Handle Results\n",
    "        if command == \"TIMEOUT\":\n",
    "            print(\"\\n[SYSTEM] Retry? Press ENTER to try again, or ESC to quit.\")\n",
    "            key = msvcrt.getch()\n",
    "            if key == b'\\x1b': break\n",
    "            continue # Loop again\n",
    "            \n",
    "        action_plan = get_mission_plan(command)\n",
    "            \n",
    "        if action_plan:\n",
    "            print(\"\\n[VERIFICATION RESULT]\")\n",
    "            print(json.dumps(action_plan, indent=4))\n",
    "            print(\">> STATUS: SUCCESS (Plan Generated)\")\n",
    "                \n",
    "            # STOPING HERE\n",
    "            print(\"[SYSTEM] Mission complete. Stopping script.\")\n",
    "            break \n",
    "        else:\n",
    "            print(\">> STATUS: FAILED (Model returned empty plan)\")\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb579306",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b36c9a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "import msvcrt\n",
    "import whisper\n",
    "import speech_recognition as sr\n",
    "import torch\n",
    "import numpy as np\n",
    "import wave"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa83c096",
   "metadata": {},
   "source": [
    "### LLM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "557fdc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_MODEL = \"mistral\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed142e9",
   "metadata": {},
   "source": [
    "### VOICE RECOGNITION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddfd17ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading turbo model on cuda...\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"turbo\" \n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Loading {MODEL_NAME} model on {device}...\")\n",
    "model = whisper.load_model(MODEL_NAME, device=device)\n",
    "\n",
    "def audio_by_user():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone(sample_rate=16000) as source: # Force 16kHz\n",
    "        print(\"Say: 'Robot, move forward one meter.'\")\n",
    "        \n",
    "        print(\"Listening...\")\n",
    "        audio = recognizer.listen(source, timeout=6, phrase_time_limit=10)\n",
    "        \n",
    "        with open(\"debug_audio.wav\", \"wb\") as f:\n",
    "            f.write(audio.get_wav_data())\n",
    "        print(\"Audio saved to 'debug_audio.wav'. Listen to it to check for noise/static.\")\n",
    "\n",
    "        # Transcribe\n",
    "        audio_data = np.frombuffer(audio.get_raw_data(), np.int16).flatten().astype(np.float32) / 32768.0\n",
    "        result = model.transcribe(audio_data, language=\"en\", fp16=torch.cuda.is_available())\n",
    "        \n",
    "        user_speech = print(f\"\\nWhisper Result: \\\"{result['text'].strip()}\\\"\")\n",
    "\n",
    "    return user_speech\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e9d5bc",
   "metadata": {},
   "source": [
    "### LLM PROCESSING FOR ROBOT CODE GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "421807b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mission_plan(user_input):\n",
    "    print(f\"[BRAIN] Processing logic with {LLM_MODEL}...\")\n",
    "\n",
    "    # STRICT System Prompt\n",
    "    # We tell the LLM exactly what objects exist so it doesn't hallucinate \"yellow_box\"\n",
    "    system_manual = \"\"\"\n",
    "    You are a Robot Logic Unit.\n",
    "    \n",
    "    ENVIRONMENT:\n",
    "    - OBJECTS: ['red_box', 'green_box', 'blue_box']\n",
    "    - LOCATIONS: ['home_position', 'table_center']\n",
    "    \n",
    "    COMMANDS ALLOWED:\n",
    "    - 'pick_up(target)'\n",
    "    - 'move_to(target)'\n",
    "    - 'place_at(target)'\n",
    "    \n",
    "    TASK:\n",
    "    Output a JSON object containing a list of actions based on the user's command.\n",
    "    \n",
    "    Example Input: \"Grab the red box and put it on the table.\"\n",
    "    Example Output: {\n",
    "        \"plan\": [\n",
    "            {\"action\": \"pick_up\", \"target\": \"red_box\"},\n",
    "            {\"action\": \"place_at\", \"target\": \"table_center\"}\n",
    "        ]\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = ollama.generate(\n",
    "            model=LLM_MODEL,\n",
    "            system=system_manual,\n",
    "            prompt=f\"User Command: {user_input}\",\n",
    "            format=\"json\",  # Forces JSON output mode in Ollama\n",
    "            options={\"temperature\": 0} # 0 makes it deterministic (logic > creativity)\n",
    "        )\n",
    "        \n",
    "        raw_response = response['response']\n",
    "        print(f\"[BRAIN] Raw Model Output: {raw_response}\") # Debug print\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = json.loads(raw_response)\n",
    "        \n",
    "        # Normalize: Try to find a list of actions\n",
    "        if \"plan\" in data:\n",
    "            return data[\"plan\"]\n",
    "        elif isinstance(data, list):\n",
    "            return data\n",
    "        else:\n",
    "            # If it returns a single object, wrap it in a list\n",
    "            return [data]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[BRAIN] Error: {e}\")\n",
    "        return []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f01afd84",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fb6c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import speech_recognition as sr\n",
    "import torch\n",
    "import numpy as np\n",
    "import wave\n",
    "import ollama\n",
    "import json\n",
    "import msvcrt\n",
    "import pybullet as p\n",
    "import pybullet_data\n",
    "import time\n",
    "import math \n",
    "import threading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe89fb99",
   "metadata": {},
   "source": [
    "### LLM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c73bae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_MODEL = \"mistral\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da031b4a",
   "metadata": {},
   "source": [
    "### VOICE RECOGNITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5b0f64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading turbo model on cuda...\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"turbo\" \n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" \n",
    "print(f\"Loading {MODEL_NAME} model on {device}...\")\n",
    "model = whisper.load_model(MODEL_NAME, device=device)\n",
    "\n",
    "def audio_by_user():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone(sample_rate=16000) as source: # Force 16kHzl, Trust me its better for voice cerognition, I learned it the hard way\n",
    "        print(\"\\n--- RECORDING ---\")\n",
    "        print(\"Say: 'Robot, move forward one meter.'\")\n",
    "        \n",
    "        # Adjust for noise to prevent early timeouts\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
    "        print(\"Listening...\")\n",
    "        \n",
    "        try:\n",
    "            audio = recognizer.listen(source, timeout=8, phrase_time_limit=10)\n",
    "            \n",
    "            # Optional: Save debug audio\n",
    "            # with open(\"debug_audio.wav\", \"wb\") as f:\n",
    "            #     f.write(audio.get_wav_data())\n",
    "\n",
    "            print(\"Transcribing...\")\n",
    "            \n",
    "            # Prepare audio for Whisper\n",
    "            audio_data = np.frombuffer(audio.get_raw_data(), np.int16).flatten().astype(np.float32) / 32768.0\n",
    "            \n",
    "            # Use the model instance passed to the function\n",
    "            result = model.transcribe(audio_data, language=\"en\", fp16=torch.cuda.is_available())\n",
    "            text = result['text'].strip()\n",
    "            \n",
    "            # CRITICAL FIX: Return the text, don't assign the print() result\n",
    "            print(f\"Whisper Result: \\\"{text}\\\"\")\n",
    "            return text\n",
    "        \n",
    "        except sr.WaitTimeoutError:\n",
    "            print(\"[ERROR] Listening timed out. No speech detected.\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] An error occurred: {e}\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52a96cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_by_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4084cd",
   "metadata": {},
   "source": [
    "### LLM PROCESSING FOR ROBOT CODE GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "220bf53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mission_plan(user_input):\n",
    "    print(f\"[BRAIN] Processing logic with {LLM_MODEL}...\")\n",
    "\n",
    "    # STRICT System Prompt\n",
    "    # We tell the LLM exactly what objects exist so it doesn't hallucinate \"yellow_box\"\n",
    "    system_manual = \"\"\"\n",
    "    You are a Robot Controller.\n",
    "    OBJECTS: 'red_box', 'green_box', 'blue_box'.\n",
    "    LOCATIONS: 'home', 'drop_zone'.\n",
    "    ACTIONS: \n",
    "    - 'move_to': requires 'target'\n",
    "    - 'magnet': requires 'state' ('on'/'off')\n",
    "    \n",
    "    Task: Convert command to JSON list of actions.\n",
    "    Example: \"Grab red box\" -> [{\"action\": \"move_to\", \"target\": \"red_box\"}, {\"action\": \"magnet\", \"state\": \"on\"}, {\"action\": \"move_to\", \"target\": \"home\"}]\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = ollama.generate(\n",
    "            model=LLM_MODEL,\n",
    "            system=system_manual,\n",
    "            prompt=f\"User Command: {user_input}\",\n",
    "            format=\"json\",  # Forces JSON output mode in Ollama\n",
    "            options={\"temperature\": 0} # 0 makes it deterministic (logic > creativity)\n",
    "        )\n",
    "        \n",
    "        raw_response = response['response']\n",
    "        print(f\"[BRAIN] Raw Model Output: {raw_response}\") # Debug print\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = json.loads(raw_response)\n",
    "        \n",
    "        # Normalize: Try to find a list of actions\n",
    "        if \"plan\" in data:\n",
    "            return data[\"plan\"]\n",
    "        elif isinstance(data, list):\n",
    "            return data\n",
    "        else:\n",
    "            # If it returns a single object, wrap it in a list\n",
    "            return [data]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[BRAIN] Error: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d47a08",
   "metadata": {},
   "source": [
    "### INITIALIZE SIMULATION IN PYBULLET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba55c6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBOT_ID = None\n",
    "END_EFFECTOR_INDEX = 6\n",
    "OBJECTS = {}   # Stores ID of red_box, blue_box, etc.\n",
    "LOCATIONS = {} # Stores coordinates of home, drop_zone\n",
    "MAGNET_CONSTRAINT = None # Stores the ID of the connection when holding an object\n",
    "SIM_ACTIVE = True\n",
    "\n",
    "def setup_world():\n",
    "    global ROBOT_ID, OBJECTS, LOCATIONS\n",
    "    \n",
    "    # Initialize\n",
    "    p.connect(p.GUI)\n",
    "    p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "    p.setGravity(0, 0, -9.81)\n",
    "\n",
    "    # Load Floor\n",
    "    p.loadURDF(\"plane.urdf\")\n",
    "    \n",
    "    # Load Table (Rotated 90 deg, set at proper height)\n",
    "    p.loadURDF(\"table/table.urdf\", basePosition=[0.5, 0, -0.65], baseOrientation=p.getQuaternionFromEuler([0, 0, 1.57]))\n",
    "\n",
    "    # Load Robot (Kuka IIWA)\n",
    "    # Mounted at the edge (0.1, 0, 0) sitting ON the table\n",
    "    ROBOT_ID = p.loadURDF(\"kuka_iiwa/model.urdf\", basePosition=[0.1, 0, 0], useFixedBase=True)\n",
    "    \n",
    "    # Define Locations\n",
    "    LOCATIONS = {\n",
    "        \"home\": [0.3, 0, 0.6],\n",
    "        \"drop_zone\": [0.0, 0.5, 0.4] \n",
    "    }\n",
    "\n",
    "    # Spawn Boxes (Helper function called inside)\n",
    "    OBJECTS[\"red_box\"] = spawn_box([0.6, 0.2, 0.1], [1, 0, 0, 1])\n",
    "    OBJECTS[\"green_box\"] = spawn_box([0.6, 0.0, 0.1], [0, 1, 0, 1])\n",
    "    OBJECTS[\"blue_box\"] = spawn_box([0.6, -0.2, 0.1], [0, 0, 1, 1])\n",
    "\n",
    "def spawn_box(pos, color_rgba):\n",
    "    # Spawns a box and colors it\n",
    "    box_id = p.loadURDF(\"cube.urdf\", basePosition=pos, globalScaling=0.08)\n",
    "    p.changeVisualShape(box_id, -1, rgbaColor=color_rgba)\n",
    "    return box_id\n",
    "\n",
    "def get_coordinate(name):\n",
    "    # Returns [x,y,z] for a name (box or location)\n",
    "    if name in OBJECTS:\n",
    "        pos, _ = p.getBasePositionAndOrientation(OBJECTS[name])\n",
    "        return list(pos)\n",
    "    elif name in LOCATIONS:\n",
    "        return LOCATIONS[name]\n",
    "    return None\n",
    "\n",
    "def move_arm(target_pos):\n",
    "    print(f\"[ROBOT] Moving to {target_pos}...\")\n",
    "    \n",
    "    # Orientation: Gripper pointing down\n",
    "    orn = p.getQuaternionFromEuler([0, 3.14, 0])\n",
    "    \n",
    "    # Inverse Kinematics calculation\n",
    "    joint_poses = p.calculateInverseKinematics(\n",
    "        ROBOT_ID, \n",
    "        END_EFFECTOR_INDEX, \n",
    "        target_pos, \n",
    "        orn,\n",
    "        maxNumIterations=100\n",
    "    )\n",
    "\n",
    "    # Apply movement to motors\n",
    "    for i in range(len(joint_poses)):\n",
    "        p.setJointMotorControl2(ROBOT_ID, i, p.POSITION_CONTROL, joint_poses[i], force=500)\n",
    "    \n",
    "    # Small blocking delay to let it travel\n",
    "    time.sleep(1.5)\n",
    "\n",
    "def toggle_magnet(state):\n",
    "    global MAGNET_CONSTRAINT\n",
    "    \n",
    "    # Get current position of the gripper\n",
    "    ee_pos = p.getLinkState(ROBOT_ID, END_EFFECTOR_INDEX)[0]\n",
    "    \n",
    "    if state == \"on\":\n",
    "        # Find closest object\n",
    "        closest_obj = None\n",
    "        min_dist = 0.2 # 20cm search radius\n",
    "\n",
    "        for name, obj_id in OBJECTS.items():\n",
    "            obj_pos, _ = p.getBasePositionAndOrientation(obj_id)\n",
    "            dist = np.linalg.norm(np.array(ee_pos) - np.array(obj_pos))\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                closest_obj = obj_id\n",
    "        \n",
    "        # If found and not already holding something\n",
    "        if closest_obj is not None and MAGNET_CONSTRAINT is None:\n",
    "            print(f\"[ROBOT] Magnet ON. Attached to object {closest_obj}\")\n",
    "            # Create a fixed link between gripper and box\n",
    "            MAGNET_CONSTRAINT = p.createConstraint(\n",
    "                ROBOT_ID, END_EFFECTOR_INDEX, \n",
    "                closest_obj, -1, \n",
    "                p.JOINT_FIXED, [0, 0, 0], [0, 0, 0], [0, 0, 0]\n",
    "            )\n",
    "        else:\n",
    "            print(\"[ROBOT] Magnet ON. No object found nearby.\")\n",
    "\n",
    "    elif state == \"off\":\n",
    "        if MAGNET_CONSTRAINT is not None:\n",
    "            print(\"[ROBOT] Magnet OFF. Object dropped.\")\n",
    "            p.removeConstraint(MAGNET_CONSTRAINT)\n",
    "            MAGNET_CONSTRAINT = None\n",
    "\n",
    "def physics_thread():\n",
    "    # This runs in the background to keep gravity working\n",
    "    while SIM_ACTIVE:\n",
    "        p.stepSimulation()\n",
    "        time.sleep(1./240.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b610effd",
   "metadata": {},
   "source": [
    "### MAIN LOOP THAT CONTROLS ALL 3 PARTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b985d570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Loading Whisper Model ---\n",
      "--- 2. Setting up PyBullet ---\n",
      "[ROBOT] Moving to [0.3, 0, 0.6]...\n",
      "\n",
      "--- RECORDING ---\n",
      "Say: 'Robot, move forward one meter.'\n",
      "Listening...\n",
      "Transcribing...\n",
      "Whisper Result: \"Go to red box.\"\n",
      "[USER] Heard: \"Go to red box.\"\n",
      "[BRAIN] Processing logic with mistral...\n",
      "[BRAIN] Raw Model Output: {\"action\": \"move_to\", \"target\": \"red_box\"}\n",
      "[PLAN] Executing 1 steps...\n",
      "[ROBOT] Moving to [0.5999970930564358, 0.2003142621971403, 0.08998860621253653]...\n",
      "[SYSTEM] Execution finished.\n",
      "\n",
      "--- RECORDING ---\n",
      "Say: 'Robot, move forward one meter.'\n",
      "Listening...\n",
      "Transcribing...\n",
      "Whisper Result: \"Turn on turn on magnet\"\n",
      "[USER] Heard: \"Turn on turn on magnet\"\n",
      "[BRAIN] Processing logic with mistral...\n",
      "[BRAIN] Raw Model Output: {\"action\": \"magnet\", \"state\": \"on\"}\n",
      "[PLAN] Executing 1 steps...\n",
      "[ROBOT] Magnet ON. Attached to object 3\n",
      "[SYSTEM] Execution finished.\n",
      "\n",
      "--- RECORDING ---\n",
      "Say: 'Robot, move forward one meter.'\n",
      "Listening...\n",
      "Transcribing...\n",
      "Whisper Result: \"Go to home position.\"\n",
      "[USER] Heard: \"Go to home position.\"\n",
      "[BRAIN] Processing logic with mistral...\n",
      "[BRAIN] Raw Model Output: {\"action\": \"move_to\", \"target\": \"home\"}\n",
      "[PLAN] Executing 1 steps...\n",
      "[ROBOT] Moving to [0.3, 0, 0.6]...\n",
      "[SYSTEM] Execution finished.\n",
      "\n",
      "--- RECORDING ---\n",
      "Say: 'Robot, move forward one meter.'\n",
      "Listening...\n",
      "[ERROR] Listening timed out. No speech detected.\n",
      "\n",
      "--- RECORDING ---\n",
      "Say: 'Robot, move forward one meter.'\n",
      "Listening...\n",
      "Transcribing...\n",
      "Whisper Result: \"Turn off magnet.\"\n",
      "[USER] Heard: \"Turn off magnet.\"\n",
      "[BRAIN] Processing logic with mistral...\n",
      "[BRAIN] Raw Model Output: {\"action\": \"magnet\", \"state\": \"off\"}\n",
      "[PLAN] Executing 1 steps...\n",
      "[ROBOT] Magnet OFF. Object dropped.\n",
      "[SYSTEM] Execution finished.\n",
      "\n",
      "--- RECORDING ---\n",
      "Say: 'Robot, move forward one meter.'\n",
      "Listening...\n",
      "Transcribing...\n",
      "Whisper Result: \"Go to blue box.\"\n",
      "[USER] Heard: \"Go to blue box.\"\n",
      "[BRAIN] Processing logic with mistral...\n",
      "[BRAIN] Raw Model Output: {\"action\": \"move_to\", \"target\": \"blue_box\"}\n",
      "[PLAN] Executing 1 steps...\n",
      "[ROBOT] Moving to [0.5999952352836073, -0.19889033106493, 0.08998860546142365]...\n",
      "[SYSTEM] Execution finished.\n",
      "\n",
      "--- RECORDING ---\n",
      "Say: 'Robot, move forward one meter.'\n",
      "Listening...\n",
      "Transcribing...\n",
      "Whisper Result: \"Turn on magnet and go home position.\"\n",
      "[USER] Heard: \"Turn on magnet and go home position.\"\n",
      "[BRAIN] Processing logic with mistral...\n",
      "[BRAIN] Raw Model Output: {\"action\": \"magnet\", \"state\": \"on\"}\n",
      "[PLAN] Executing 1 steps...\n",
      "[ROBOT] Magnet ON. Attached to object 5\n",
      "[SYSTEM] Execution finished.\n",
      "\n",
      "--- RECORDING ---\n",
      "Say: 'Robot, move forward one meter.'\n",
      "Listening...\n",
      "Transcribing...\n",
      "Whisper Result: \"go to home position.\"\n",
      "[USER] Heard: \"go to home position.\"\n",
      "[BRAIN] Processing logic with mistral...\n",
      "[BRAIN] Raw Model Output: {\"action\": \"move_to\", \"target\": \"home\"}\n",
      "[PLAN] Executing 1 steps...\n",
      "[ROBOT] Moving to [0.3, 0, 0.6]...\n",
      "[SYSTEM] Execution finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-3 (physics_thread):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Userl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"d:\\envoirment1\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"C:\\Users\\Userl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\Userl\\AppData\\Local\\Temp\\ipykernel_53236\\1649454323.py\", line 113, in physics_thread\n",
      "pybullet.error: Not connected to physics server.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RECORDING ---\n",
      "Say: 'Robot, move forward one meter.'\n",
      "Listening...\n",
      "[ERROR] Listening timed out. No speech detected.\n",
      "\n",
      "[SYSTEM] Stopping...\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "Not connected to physics server.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31merror\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     63\u001b[39m SIM_ACTIVE = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     64\u001b[39m t.join()\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdisconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31merror\u001b[39m: Not connected to physics server."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # A. Setup for Whisper\n",
    "    print(\"--- 1. Loading Whisper Model ---\")\n",
    "    whisper_model = whisper.load_model(MODEL_NAME, device=device)\n",
    "    \n",
    "    print(\"--- 2. Setting up PyBullet ---\")\n",
    "    setup_world()\n",
    "    \n",
    "    # B. Start Physics in Background Thread\n",
    "    t = threading.Thread(target=physics_thread)\n",
    "    t.start()\n",
    "    \n",
    "    # Move to starting position, for me it was convinient for keep the robot in the home position\n",
    "    move_arm(LOCATIONS[\"home\"])\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # To make The code observations easier it stops here until ENTER is pressed to make it ready.\n",
    "            input(\"\\n[USER] >>> Press ENTER to start listening... (or Ctrl+C to exit)\")\n",
    "\n",
    "            # Listen\n",
    "            user_text = audio_by_user()\n",
    "            \n",
    "            if user_text:\n",
    "                print(f\"[USER] Heard: \\\"{user_text}\\\"\")\n",
    "                \n",
    "                if \"exit\" in user_text.lower():\n",
    "                    break\n",
    "                \n",
    "                # D. Plan\n",
    "                plan = get_mission_plan(user_text)\n",
    "                \n",
    "                # E. Execute\n",
    "                if plan:\n",
    "                    print(f\"[PLAN] Executing {len(plan)} steps...\")\n",
    "                    for step in plan:\n",
    "                        action = step.get('action')\n",
    "                        \n",
    "                        if action == \"move_to\":\n",
    "                            target = step.get('target')\n",
    "                            coords = get_coordinate(target)\n",
    "                            \n",
    "                            if coords:\n",
    "                                if \"box\" in target: \n",
    "                                    coords[2] += 0.05\n",
    "                                move_arm(coords)\n",
    "                            else:\n",
    "                                print(f\"[ERROR] Unknown target: {target}\")\n",
    "\n",
    "                        elif action == \"magnet\":\n",
    "                            state = step.get('state')\n",
    "                            toggle_magnet(state)\n",
    "                            \n",
    "                        time.sleep(0.5)\n",
    "                    \n",
    "                    print(\"[SYSTEM] Execution finished.\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n[SYSTEM] Stopping...\")\n",
    "\n",
    "    finally:\n",
    "        SIM_ACTIVE = False\n",
    "        t.join()\n",
    "        p.disconnect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
